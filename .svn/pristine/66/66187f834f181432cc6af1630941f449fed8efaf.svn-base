\section{Introduction}
\label{sec:intro}

A vital enabler for high consolidation ratios of virtual machines
in virtualization based hosting platforms
is memory overcommitment. 
%
The main idea of techniques relying in overcommitment 
exploit the tradeoff between
of dynamic memory provisioning and usage efficiency, and 
performance implications.
%
%Efficient memory management in virtualized
%systems enables increased virtual machine {\em consolidation density} 
%through higher levels of memory utilization.
%
%Increased memory efficiency results in higher levels of hardware
%availability and cost efficiency in terms of hardware,
%maintenance and power.
%
%Additional software layers in systems hosting multiple isolated execution 
%domains---hypervisors in virtualized systems~\cite{xen,kvm,vmware}, and,
%hypervisors and/or container 
%frameworks in nested virtualized systems~\cite{cgroup,docker,lxc}---present 
%several challenges in efficient resource management.
%
The challenge of memory management in virtualized systems~\cite{xen,kvm,vmware}
and container-based systems~\cite{cgroup,docker,lxc} is 
the opaquness between the resource manager (the hypervisor or
the host operating system) and the resource user (guest operating
systems or applications).
%
%One of the main bottlenecks in these systems is the increased 
%opaqueness between the resource manager (hypervisor) and 
%the resource user (applications).
%
Techniques like dynamic ballooning~\cite{vmware,hotplug}, memory
content deduplication~\cite{vmware,ksmpaper} and hypervisor 
caching~\cite{memtrans,oracletmem,kvmzcache} 
%address the challenges by enabling 
enable dynamic provisioning, increased memory efficiency and 
system level disk cache provisioning for efficient memory 
management in virtualized systems.
%
While these techniques and associated policies have been studied
extensively in virtualization setups~\cite{memmgmnt,mascots, synergy, x, y,z},
they have not be studied in the \emph{nested hosting} setups, or
what we refer to as the \emph{derivative cloud}.
%
A \emph{derivative cloud} is essentially a nested setup, virtual machines
nested in virtual machines~\cite{xenblanket} or containers deployed in 
virtual machine~\cite{spotcheck, google}, 
the latter being the focus of this work.
%
In the derivative model an intermediate service provider builds
her own service offering on top of service she rents, buys or leases.
%
The services themselves could be smaller sized verions of the
first-level service or could be applications and in general host
other software-as-a-service or platform-as-a-serive variants.
%
From the resource management perspective, with container based
derivative clouds, the container-based nested services
are provisioned and managed from within the virtual machines
and resouces for the virtual machines managed by the 
hypervisor-level policy tools.
%
%Containers are provisioned and managed by the VM administrators,
%who may want to employ higher level QoS policies in terms of priority or
%optimize the resource utilization depending on the application 
%characteristics.
%
%For VMs enabled with hypervisor caches, the differentiated partitioning
%Nested virtualization, recently popularized by application containers and 
%{\em Derivative clouds}~\cite{spotcheck,google}, enables hosting 
%application containers inside VMs.
%
The central proposition of this work is that resource management
techniques employed with single-level virtualization setups
are inadequate in the context of derivative clouds 
and require augumentation and re-design.
%ballooning, deduplication and hypervisor caching is required to be 
%to analyze
%effectiveness in a nested virtualization setup.
%nested virtualization framework to analyze their 
%

In this work, our focus is the use of hypervisor caching for
effective disk cache memory management in derivative clouds.
%the focus is to explore the hypervisor caching solution space 
%in nested hosting setups (containers inside VMs) and work out suitable 
%enhancements to enable efficient hypervisor caching for nested application 
%containers inside VMs.
%
Memory used to cache disk content (a.k.a. page cache) can be
a major bottleneck for efficient memory management in virtualized
systems.
%
Utility of a disk cache depends on application access behavior,
e.g., access patterns (sequential vs. random) and read-write ratios.
%
Best effort disk caches employed by operating systems greedily consume
all available free memory in the system (virtual machine in this case) 
to provision disk cache memory.
%, which may be wasteful in a multi-hosting scenario.  
%
Further, disk cache management decisions of a guest OS are 
localized to the virtual machine and are oblivious to memory 
usage and disk cache utility 
across the virtual machines hosted on the same physical machine.
%
%So, in a multi-hosting system, memory used to cache disk content 
%by applications (or operating systems), if managed
%at the system level, provide flexibility of differentiated 
%partitioning to meet system level objectives like
%application priority, cache utility etc..
%

Hypervisor caching~\cite{memtrans, oracletmem,kvmzcache, vmmexclusive,singleton} 
provides a mechanism for system-wide management of % to globally manage 
disk cache memory in virtualized systems. 
%
Hypervisor caches can be setup and used 
in two different configurations.
%
First, available free system memory can be used to setup a 
hypervisor managed second-chance cache.
%
Size of the second-chance cache and per-VM partitioning 
can be implemented based on resource management policies.
%provisioned dynamically 
%across virtual machines depending on higher level policies.
%
Second, dynamic adjustment of virtual machine memory allocations through
techniques like ballooning~\cite{vmware,hotplug} to explicitly
push the disk caching to the hypervisor, fully or partially.
%to enable system level management of memory use for disk content caching.
%
In fact, in the second configuration the page caches of guest OSes
can be offloaded to the hypervisor. 
%
The hypervisor in-turn can improve
memory efficiency by employing per-VM differentiated provisioning,
perform in-band compression and deduplication etc~\cite{oracletmem,kvmzcache}.
%State-of-the-art hypervisor caching solutions---Xen Transcendent memory~\cite{oracletmem}and KVM compressed host cache ~\cite{kvmzcache}---provide mechanisms to
%distribute the hypervisor cache across VMs depending on
%high level objectives like VM priority and cache utility.
%
However, hypervisor cache management is agnostic to the execution
entities within the virtual machine. For example, hypervisor 
caches cannot provide differential cache allocations to 
multiple applications executing within a virtual machine.
%
More specifically, with derivative
clouds current hypervisor differentiated provisioning techniques
cannot be extended to the nested entities due to the semantic
barrier of between the hypervisor and execution entities
within virtual machines.
%partitioning at a finer granularity
%(e.g., at application level) is {\em not possible} in the existing 
%framework.
%
%This is because, hypervisor caches operate in an application
%agnostic manner and are unaware of application semantics due to the 
%opaque nature of applications with respect to the hypervisor caches.
%
Enlightening the hypervisor cache with application level information 
is non-trivial because it requires understanding and redesigning
of the current integration framework. 
%

Derivative clouds provide an interesting design point---hypervisor
cognizance does not need to extend to applications but can
take cognizance of containers and still operate in an application
agnostic manner. 
%
An usage scenario would involve differentiated provisioning
of the cached on a per-VM basis and the per-VM cache
would be differentiated on a per-container basis.
%
The provisioning policies at each level would be mutually
exclusive and the same time allow each hosting entity
to influence the cache provisioning decisions.
\puru{add example here.}
%
We design techniques to address this opportunity
to provide nested container level differentation for
hypervisor cache management. 
%
A derivative cloud that hosts
applications in containers will in effect also yield application
level differentiation of the hypervisor cache.
%
%Therefore, it is difficult to realize differential treatment of cache 
%usage by different applications from within the VMs. 
% 

%

Further, recent advancements in memory technologies enable cost-effective
storage mechanisms like non-volatile memory (NVM) and solid state
devices (SSD).
%
One of the compelling usages of NVMs is to employ them
as second chance caches or hypervisor caches 
in the disk access path to improve disk access performance~\cite{extmem,sdc}.
%
%A natural usage of NVMs is to use them to implement 
%hypervisor caches to enable a second chance cache for the VMs.
%
%
%Application aware provisioning of 
Provisioning of NVM-backed hypervisor caches
in a derivative setup suffers from the same limitations as that
of memory backed hypervisor caches.
%
A hypervisor caching solution that implements
nesting aware policies (and by implication application level policies)
irrespective of the storage methods is desirable.
%
%
Moreover, enabling multiple types and adaptive configuration
capability of storage devices for
hypervisor caching 
%and their flexible configurability at the
%application level provides 
flexibility in memory management policy design.
\puru{remove this line.}
 


%
%Derivative clouds~\cite{spotcheck,google}, a recent cloud service
%delivery framework, are well suited for a layered distribution model of
%platform-as-a-service (PaaS).
%%
%In this model, an intermediate PaaS service provider dynamically
%rents VMs from a cloud provider like Amazon EC2 etc. and provisions
%application containers in the VMs to serve the end customers.
%%
%Containers are provisioned and managed by the VM administrators,
%who may want to employ higher level QoS policies in terms of priority or
%optimize the resource utilization depending on the application 
%characteristics.
%%
%For VMs enabled with hypervisor caches, the differentiated partitioning
%of any VM's hypervisor cache share across application containers is 
%simply not possible with the existing approaches.
%%
%Therefore, flexible partitioning of memory resources at two levels---across
%VMs and across containers in a VM---opens up policy design avenues to
%improve memory efficiency and application performance.
%%


%In this context of derivative clouds, flexible partitioning of hypervisor cache 
%across containers depending on high level policy is desirable.
%% hypervisor caching solutions
%%should provide 
%%
%Further, the solution
%should provide flexibility in choosing from different asymmetric cache storage 
%backends like memory and SSD.
%
%
Towards providing nested differentiated hypervisor caching in derivative 
clouds, we make the following contributions,
%our contributions are as follows,
\begin{itemize}
\item We design and implement \dd, a hypervisor caching framework
with differentiated partitioning capabilities across application
containers along with VM-level provisioning capabilities.
%
\item \dd{} provides flexibility in terms of dynamic and elastic
provisioning capabilities and configurable cache storage options
for application containers executing within VMs.
%
\item The proposed solution is capable of dynamically adapting
to changing demands and can support two levels of
independent disk cache management in the derivative cloud like 
setups.
%
\end{itemize}  

We have implemented and evaluated \dd{} with the KVM virtualization 
solution and the LXC container framework~\cite{lxc}.
%
Our results show that, \dd{} is capable of dynamically adapting to 
changing demands and can support differentiated partitioning at multiple
levels.
%
We show the efficacy of \dd{} through realistic usage scenarios 
in a derivative cloud setup for efficient provisioning of caching 
resources.
